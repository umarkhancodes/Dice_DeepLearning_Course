{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPWepzBK+7CgY9onp7j+Dl+"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"IawCzejlgyTZ"},"outputs":[],"source":["# Install packages in the current environment\n","import sys\n","!{sys.executable} -m pip install opencv-python \n","!{sys.executable} -m pip install matplotlib\n","!{sys.executable} -m pip install tqdm\n","!{sys.executable} -m pip install scikit-learn"]},{"cell_type":"code","source":["import tensorflow as tf\n","import os\n","import cv2\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import tqdm\n","from sklearn.preprocessing import LabelBinarizer"],"metadata":{"id":"xsBs68stg-Nl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["BASE_PATH = '../data/UCF-101'\n","VIDEOS_PATH = os.path.join(BASE_PATH, '**','*.avi') \n","SEQUENCE_LENGTH = 40"],"metadata":{"id":"Hbp3o1mPhAN7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def frame_generator():\n","    video_paths = tf.io.gfile.glob(VIDEOS_PATH)\n","    np.random.shuffle(video_paths)\n","    for video_path in video_paths:\n","        frames = []\n","        cap = cv2.VideoCapture(video_path) #read video\n","        num_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT)) #total frames\n","        sample_every_frame = max(1, num_frames // SEQUENCE_LENGTH)  #sample every nth frame\n","        current_frame = 0\n","\n","        label = os.path.basename(os.path.dirname(video_path))\n","\n","        max_images = SEQUENCE_LENGTH\n","        while True:\n","            success, frame = cap.read()\n","            if not success:\n","                break\n","\n","            if current_frame % sample_every_frame == 0:\n","                # OPENCV reads in BGR, tensorflow expects RGB so we invert the order\n","                frame = frame[:, :, ::-1] \n","                img = tf.image.resize(frame, (299, 299))\n","                img = tf.keras.applications.inception_v3.preprocess_input(\n","                    img)\n","                max_images -= 1\n","                yield img, video_path\n","\n","            if max_images == 0:\n","                break\n","            current_frame += 1\n","\n","# `from_generator` might throw a warning, expected to disappear in upcoming versions:\n","# https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/data/Dataset#for_example_2\n","dataset = tf.data.Dataset.from_generator(frame_generator,\n","             output_types=(tf.float32, tf.string),\n","             output_shapes=((299, 299, 3), ()))\n","\n","dataset = dataset.batch(16).prefetch(tf.data.experimental.AUTOTUNE)"],"metadata":{"id":"YkbrwkUhhBDH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["inception_v3 = tf.keras.applications.InceptionV3(include_top=False, weights='imagenet') #Feature Extractor \n","\n","x = inception_v3.output\n","\n","# We add Average Pooling to transform the feature map from\n","# 8 * 8 * 2048 to 1 x 2048, as we don't need spatial information\n","pooling_output = tf.keras.layers.GlobalAveragePooling2D()(x)\n","\n","feature_extraction_model = tf.keras.Model(inception_v3.input, pooling_output)"],"metadata":{"id":"tikt58JahGar"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["current_path = None\n","all_features = []\n","\n","for img, batch_paths in tqdm.tqdm(dataset):\n","    batch_features = feature_extraction_model(img)\n","    batch_features = tf.reshape(batch_features, \n","                              (batch_features.shape[0], -1))\n","    \n","    for features, path in zip(batch_features.numpy(), batch_paths.numpy()):\n","        if path != current_path and current_path is not None:\n","            output_path = current_path.decode().replace('.avi', '.npy')\n","            np.save(output_path, all_features)\n","            all_features = []\n","            \n","        current_path = path\n","        all_features.append(features)"],"metadata":{"id":"oqm7I7j3hJ_x"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["LABELS = ['UnevenBars','ApplyLipstick','TableTennisShot','Fencing','Mixing','SumoWrestling','HulaHoop','PommelHorse','HorseRiding','SkyDiving','BenchPress','GolfSwing','HeadMassage','FrontCrawl','Haircut','HandstandWalking','Skiing','PlayingDaf','PlayingSitar','FrisbeeCatch','CliffDiving','BoxingSpeedBag','Kayaking','Rafting','WritingOnBoard','VolleyballSpiking','Archery','MoppingFloor','JumpRope','Lunges','BasketballDunk','Surfing','SkateBoarding','FloorGymnastics','Billiards','CuttingInKitchen','BlowingCandles','PlayingCello','JugglingBalls','Drumming','ThrowDiscus','BaseballPitch','SoccerPenalty','Hammering','BodyWeightSquats','SoccerJuggling','CricketShot','BandMarching','PlayingPiano','BreastStroke','ApplyEyeMakeup','HighJump','IceDancing','HandstandPushups','RockClimbingIndoor','HammerThrow','WallPushups','RopeClimbing','Basketball','Shotput','Nunchucks','WalkingWithDog','PlayingFlute','PlayingDhol','PullUps','CricketBowling','BabyCrawling','Diving','TaiChi','YoYo','BlowDryHair','PushUps','ShavingBeard','Knitting','HorseRace','TrampolineJumping','Typing','Bowling','CleanAndJerk','MilitaryParade','FieldHockeyPenalty','PlayingViolin','Skijet','PizzaTossing','LongJump','PlayingTabla','PlayingGuitar','BrushingTeeth','PoleVault','Punch','ParallelBars','Biking','BalanceBeam','Swing','JavelinThrow','Rowing','StillRings','SalsaSpin','TennisSwing','JumpingJack','BoxingPunchingBag'] \n","encoder = LabelBinarizer()\n","encoder.fit(LABELS)"],"metadata":{"id":"30qXkhtihQZQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = tf.keras.Sequential([\n","    tf.keras.layers.Masking(mask_value=0.),\n","    tf.keras.layers.LSTM(512, dropout=0.5, recurrent_dropout=0.5),\n","    tf.keras.layers.Dense(256, activation='relu'),\n","    tf.keras.layers.Dropout(0.5),\n","    tf.keras.layers.Dense(len(LABELS), activation='softmax') # classification\n","])"],"metadata":{"id":"SJtRiOYjhSYT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.compile(loss='categorical_crossentropy',\n","              optimizer='rmsprop',\n","              metrics=['accuracy', 'top_k_categorical_accuracy'])"],"metadata":{"id":"Ay59085HhTF5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# to do \n","test_file = os.path.join('data', 'testlist01.txt')\n","train_file = os.path.join('data', 'trainlist01.txt')\n","\n","with open('data/testlist01.txt') as f:\n","    test_list = [row.strip() for row in list(f)]\n","\n","with open('data/trainlist01.txt') as f:\n","    train_list = [row.strip() for row in list(f)]\n","    train_list = [row.split(' ')[0] for row in train_list]\n","\n","\n","def make_generator(file_list):\n","    def generator():\n","        np.random.shuffle(file_list)\n","        for path in file_list:\n","            full_path = os.path.join(BASE_PATH, path).replace('.avi', '.npy')\n","\n","            label = os.path.basename(os.path.dirname(path))\n","            features = np.load(full_path)\n","\n","            padded_sequence = np.zeros((SEQUENCE_LENGTH, 2048))\n","            padded_sequence[0:len(features)] = np.array(features)\n","\n","            transformed_label = encoder.transform([label])\n","            yield padded_sequence, transformed_label[0]\n","    return generator"],"metadata":{"id":"6DRhUNbGhU1w"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_dataset = tf.data.Dataset.from_generator(make_generator(train_list),\n","                 output_types=(tf.float32, tf.int16),\n","                 output_shapes=((SEQUENCE_LENGTH, 2048), (len(LABELS))))\n","train_dataset = train_dataset.batch(16).prefetch(tf.data.experimental.AUTOTUNE)\n","\n","\n","valid_dataset = tf.data.Dataset.from_generator(make_generator(test_list),\n","                 output_types=(tf.float32, tf.int16),\n","                 output_shapes=((SEQUENCE_LENGTH, 2048), (len(LABELS))))\n","valid_dataset = valid_dataset.batch(16).prefetch(tf.data.experimental.AUTOTUNE)"],"metadata":{"id":"IcQw9ZtqhW0u"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir='/tmp', update_freq=1000) \n","model.fit(train_dataset, epochs=17, callbacks=[tensorboard_callback], validation_data=valid_dataset"],"metadata":{"id":"Pacv1IO_hY5Z"},"execution_count":null,"outputs":[]}]}